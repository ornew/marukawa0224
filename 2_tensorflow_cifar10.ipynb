{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 by TensorFlow on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Copyright © 2018 by Arata Furukawa. (http://ornew.net)</small>\n",
    "\n",
    "<small style=\"font-size:0.5em;\">この資料は「機械学習アプリを「賢く」作る：Amazon SageMakerクラウド・ハンズオン」のために作成されたものです。ノートブックをダウンロードし、持ち帰って自由に実行・加工していただいて構いませんが、解説文の外部への公開・転載はご遠慮ください。</small>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)という分類問題を解いてみましょう。CIFAR10は以下の10種類の画像を分類する問題です。\n",
    "\n",
    "1. 飛行機\n",
    "2. 自動車\n",
    "3. 鳥\n",
    "4. 猫\n",
    "5. 鹿\n",
    "6. 犬\n",
    "7. カエル\n",
    "8. 馬\n",
    "9. 船\n",
    "10. トラック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://marukawa0224-XX/tensorflow'\n",
    "base_job_name = 'marukawa0224-XX-cifar10-job'\n",
    "print('output_path:\\n\\t{}'.format(output_path))\n",
    "print('base_job_name:\\n\\t{}'.format(base_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際はデータのダウンロードと変換とアップロードが必要ですが、MNISTと違いそこそこ時間がかかるため、ハンズオンでは事前にS3上にアップロードしたものをご利用ください。(持ち帰ってご自身で実行される場合は以下のプログラムを参考にしてください。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def convert_tfrecord(filename, images, labels):\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    with tf.python_io.TFRecordWriter(filename, options) as tfrecord:\n",
    "        for image, label in zip(images, labels):\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image' : tf.train.Feature(\n",
    "                    float_list=tf.train.FloatList(\n",
    "                        value=image.flatten() / 255.)),\n",
    "                'label' : tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(value=label)),\n",
    "            }))\n",
    "            tfrecord.write(example.SerializeToString())\n",
    "\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "data_dir = 'data/cifar10'\n",
    "tf.gfile.MakeDirs(data_dir)\n",
    "convert_tfrecord(os.path.join(data_dir,'train.tfr'), train[0], train[1])\n",
    "convert_tfrecord(os.path.join(data_dir,'test.tfr'), test[0], test[1])\n",
    "\n",
    "data_dir = session.upload_data(data_dir, session.default_bucket(), data_dir)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 's3://sagemaker-seminar-data/cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムの説明の前に、学習を実行しましょう。しばらく時間がかかります。\n",
    "\n",
    "job_nameやendpoint_nameは、もし途中で誤って中断してしまった場合や、あとから再度アタッチするのに必要な情報ですので、表示を残しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'save_summary_steps'       : 10,\n",
    "    'point_multiplier'         : 1,\n",
    "    'depth_multiplier'         : 1,\n",
    "    'learning_rate'            : 0.5,\n",
    "    'dropout_rate'             : 0.5,\n",
    "    'batch_size'               : 512,\n",
    "    'shuffle_buffer_size'      : 1024,\n",
    "    'weight_decay'             : 2e-4,\n",
    "    'tfrecord_compression_type': 'GZIP',\n",
    "    # tfrecord_compression_typeは、convert_tfrecordの時に\n",
    "    # 指定した圧縮オプションと一致する必要があります\n",
    "    # 事前アップロードしたものはGZIPです\n",
    "}\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(\n",
    "    entry_point='./code/cifar10.py',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    output_path=output_path,\n",
    "    code_location=output_path,\n",
    "    training_steps=10000,\n",
    "    evaluation_steps=1000,\n",
    "    base_job_name=base_job_name,\n",
    "    \n",
    "    #########################################################\n",
    "    # ハンズオンでは以下の設定を絶対に変えないでください！！！\n",
    "    # 他の方が実行できなくなったり、高額な課金が発生することがあります。\n",
    "    # 異常な課金等を確認した場合、請求額を追加徴収させて頂きます。\n",
    "    #########################################################\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_tensorboard_locally`を指定するとTensorBoardも起動します。\n",
    "\n",
    "<a href=\"/proxy/6006/\" target=\"_blank\">新しいタブでTensorBoardを開く</a>(下のセルのfitを実行してからアクセスしてください)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(data_dir, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中級テクニックの解説\n",
    "\n",
    "ここから、今学習を実行しているモデルの解説をします。もし学習が早く終わったら、後ろの方の「デプロイ」を実行しておいても構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet\n",
    "\n",
    "事前に用意したモデルでは、Googleの**MobileNet**というネットワーク構造を使っています。\n",
    "\n",
    "最先端のモデルには若干精度で劣りますが、GoogleNetやVGG16といった有名なネットワークよりも高精度のベンチマークを出しています。\n",
    "\n",
    "MobileNetの特徴として、\n",
    "\n",
    "- 精度に対してパラメータ数が少ない\n",
    "- パラメータ数が少ないので、計算負荷やモデルサイズが小さい\n",
    "- 近年高精度を出している複雑なハイウェイ構造を持っていないため、とてもシンプルで理解しやすい\n",
    "\n",
    "といった事が挙げられます。負荷が小さいため、名前の通りモバイル環境でも実行可能なモデルとして注目されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetには、ディープラーニングによる画像認識における重要なテクニックが幾つも盛り込まれています。いくつかの重要なテクニックについてピックアップして解説をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetの構造\n",
    "\n",
    "MobileNetを簡単に実装すると、以下のようなプログラムになります。\n",
    "\n",
    "```python\n",
    "# 畳み込みのブロック\n",
    "def conv_block(x, filters, strides):\n",
    "    x = tf.layers.conv2d(x, filters, 3, strides, 'same', use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=is_training)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "# 分離型畳み込みのブロック\n",
    "def sepconv_block(x, filters, strides):\n",
    "    x = tf.layers.separable_conv2d(x, filters, 3, strides, 'same', use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=is_training)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "with tf.variable_scope('mobilenet'):\n",
    "    x =    conv_block(x, 32  , 2, '32-2')\n",
    "    x = sepconv_block(x, 64  , 1, '64-1')\n",
    "    x = sepconv_block(x, 128 , 2, '128-2')\n",
    "    x = sepconv_block(x, 128 , 1, '128-1')\n",
    "    x = sepconv_block(x, 256 , 2, '256-2')\n",
    "    x = sepconv_block(x, 256 , 1, '256-1')\n",
    "    x = sepconv_block(x, 512 , 2, '512-2')\n",
    "    x = sepconv_block(x, 512 , 1, '512-1-0')\n",
    "    x = sepconv_block(x, 512 , 1, '512-1-1')\n",
    "    x = sepconv_block(x, 512 , 1, '512-1-2')\n",
    "    x = sepconv_block(x, 512 , 1, '512-1-3')\n",
    "    x = sepconv_block(x, 512 , 1, '512-1-4')\n",
    "    x = sepconv_block(x, 1024, 2, '1024-2')\n",
    "    x = sepconv_block(x, 1024, 1, '1024-1')\n",
    "```\n",
    "\n",
    "畳み込みのブロックが1個、その後に分離型畳み込みのブロックが13個繋がったモデルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ブロックは、**入力 → (分離型)畳み込み → バッチ正規化 → ReLU(活性化関数) → 出力**という流れになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構造については、[TensorBoard](/proxy/6006/#graphs)も参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み層\n",
    "\n",
    "MNISTの例では、$xW + b$という形の密結合（Densely Connected, 総結合=Fully Connectedとも）層を使いました。畳み込み層では、$W$と$x$について行列積の代わりに畳み込みという計算を行います。\n",
    "\n",
    "畳み込み演算は、ディープラーニング以前から信号処理や画像処理で用いられていた計算で、画像の場合はエッジ抽出などの特徴抽出を行う処理として活用されていました。\n",
    "\n",
    "![](https://i.imgur.com/6yBG7LC.png)\n",
    "（図）簡略化のためにチャネル方向の次元を省略しているので注意。それぞれのサイズや数もあくまで一例です。\n",
    "\n",
    "局所的な空間情報に基づく特徴の抽出が行えるため、画像認識におけるニューラルネットワークでは必ずと言っていいほど使われています。密結合に比べて計算量は多くなりますが、パラメータ数は少なくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分離型畳み込み層（Separable Convolutional Layer）\n",
    "\n",
    "通常の畳み込みをDepthwise（深度毎）とPointwise（位置毎）の2回の畳み込みに分離したものです。カーネルパラメータを低次元の2つのカーネルパラメータで近似することで、精度をある程度維持しながらパラメータ数を減らす事ができます。使う側としては通常の畳み込み層と同じように使えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ正規化（Batch Normalization）\n",
    "\n",
    "![](https://i.imgur.com/gJ9Tg3k.png)\n",
    "\n",
    "（図）入力データはミニバッチ。バッチ方向のデータ（青く塗りつぶされた部分）が、平均0、分散1となるように正規化を行う。これを位置ごとに行う。\n",
    "\n",
    "MNISTの例では、一度の学習につき複数枚の入力を同時に行いました。入力のまとまりをバッチと呼びます。厳密には、全てのデータセットのまとまりをバッチといい、そこからランダムに選択した複数の入力をミニバッチと言いますが、まとめてバッチと呼称することもあります。\n",
    "\n",
    "バッチ正規化では、位置毎にバッチ方向で入力データの正規化を行います。（図を参照）\n",
    "\n",
    "内部共変量シフトが抑制されることで学習が安定します。学習係数を高く設定することができるようになり、収束速度が高速化します。正則化の効果もあり、勾配が爆発したり消失する現象を抑え、より層の深いネットワークの学習を可能にします。また、パラメータの初期値の影響を小さくしたり、データのばらつきによる過学習を抑える効果もあります。\n",
    "\n",
    "共変量シフトとは、例えばデータのばらつきなどが原因で、関数の想定する入力分布と実際の入力分布が変わってしまう現象のことです。多層のニューラルネットワークの内部では中間層の出力が次の層の入力となりますが、この入力も同じように共変量シフトが発生します。これを内部共変量シフトと呼び、深いネットワークの学習に大きな悪影響を与えることが知られています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU（Rectified Linear Unit）\n",
    "\n",
    "ReLUは整流器と呼ばれる関数です。定義はシンプルで、$\\max(x, 0)$です。一般的にはランプ関数と呼ばれます。入力が正数であれば入力をそのまま出力し、入力が負数であれば0を出力します。\n",
    "\n",
    "ディープニューラルネットワークは層を広く深くすることで十分な表現力を獲得したため、活性化関数の非線形性が精度に与える影響は非常に小さくなりました。むしろ、活性化関数の影響で誤差逆伝搬中に勾配が非常に小さくなり学習が困難になる勾配消失の問題が発生します。区分線形関数であるReLUは、非線形関数でありながら微分値は1か0のいずれかであるため、誤差逆伝搬中に勾配の消失を引き起こさずに、深いネットワークの学習を可能にします。ReLUは微分不可能な点を持ちますが、計算上は劣微分で処理します。勾配計算が単純で高速であるのも特徴です。派生した関数も多く、上限値が設定されたもの、負の区間における勾配を変更したもの、パラメトリックなもの、微分可能に拡張したものなどがあります。深いネットワークにおけるデファクトスタンダードと言える重要な活性化関数です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 読み出し層の構造\n",
    "\n",
    "MobileNetによってフィーチャを変換したのち、そこから目的となる10個のラベルの確率分布に変換するための読み出し層を定義します。\n",
    "\n",
    "```python\n",
    "# 読み出し層\n",
    "with tf.variable_scope('readout_layer'):\n",
    "    x = tf.reduce_mean(x, [1, 2], keep_dims=True, name='global_average_pooling')\n",
    "    x = tf.layers.dropout(x, rate=0.5, training=is_training)\n",
    "    x = tf.layers.conv2d(x, CATEGORY_NUM, 1)\n",
    "    x = tf.squeeze(x, [1,2])\n",
    "\n",
    "# 出力\n",
    "logits = tf.identity(x, name='logits')\n",
    "probabilities = tf.nn.softmax(logits, name='probabilities')\n",
    "```\n",
    "\n",
    "総平均プーリング層、ドロップアウト層、畳み込み層を経て、最後にSoftmax関数です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 総平均プーリング層（Global Average Pooling Layer）\n",
    "\n",
    "平均プーリングとは、一定の範囲をその平均値に集約（プーリング）する操作です。総平均プーリングでは、入力レイヤー全体（今回の画像で言えば、高さと幅の軸で構成される面）単位で平均を取るプーリングを行います。畳み込みニューラルネットワークは、最後の読み出し層のパラメータ数がとても大きくなる傾向があります。読み出し層の前に適用することで読み出し層の重みパラメータ数を抑えることができます。このような一般的な畳み込みネットワークの読み出し層の前で総平均プーリングをしても精度に大きな影響はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ドロップアウト層（Dropout Layer）\n",
    "\n",
    "学習の際に、ランダムにパラメータをドロップアウトする（存在しないものとして扱う）ことで、データの偏りによるモデルの過学習を抑えます。ただし、学習速度が遅くなる欠点があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = estimator.deploy(\n",
    "    #########################################################\n",
    "    # ハンズオンでは以下の設定を絶対に変えないでください！！！\n",
    "    # 他の方が実行できなくなったり、高額な課金が発生することがあります。\n",
    "    # 異常な課金があった場合、請求額を追加徴収させて頂きます。\n",
    "    #########################################################\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium')\n",
    "print('Endpoint:\\n\\t{}'.format(api.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.predictor import tf_serializer, tf_deserializer\n",
    "predictor = sagemaker.RealTimePredictor(endpoint=api.endpoint,\n",
    "                              deserializer=tf_deserializer, \n",
    "                              serializer=tf_serializer,\n",
    "                              content_type='application/octet-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.tensorflow_serving.apis import predict_pb2\n",
    "def create_request(data):\n",
    "    tensor_proto = tf.make_tensor_proto(\n",
    "        values=data, shape=[1, 32, 32, 3], dtype=tf.float32)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = 'generic_model'\n",
    "    request.model_spec.signature_name = 'predictions'\n",
    "    request.inputs['images'].CopyFrom(tensor_proto)\n",
    "    return request\n",
    "\n",
    "labels = [\n",
    "    '飛行機',\n",
    "    '自動車',\n",
    "    '鳥',\n",
    "    '猫',\n",
    "    '鹿',\n",
    "    '犬',\n",
    "    'カエル',\n",
    "    '馬',\n",
    "    '船',\n",
    "    'トラック',\n",
    "]\n",
    "\n",
    "def predict(image, label):\n",
    "    result = predictor.predict(create_request(image.tolist()))\n",
    "    plt.bar(np.arange(10), result.outputs['probabilities'].float_val)\n",
    "    plt.ylim(ymax=1)\n",
    "    plt.show()\n",
    "    predict = result.outputs['classes'].int64_val[0]\n",
    "    print('答え={} 予測={}'.format(labels[label], labels[predict]))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_data = json.load(open('cifar10.test.json'))\n",
    "\n",
    "for i in xrange(len(test_data['labels'])):\n",
    "    image = test_data['data'][i]\n",
    "    label = test_data['labels'][i]\n",
    "    predict(np.asarray(image).astype(float) / 255., label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
